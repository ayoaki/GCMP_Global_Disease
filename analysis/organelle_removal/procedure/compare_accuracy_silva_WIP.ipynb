{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from qiime2 import Artifact\n",
    "from qiime2.plugins.feature_classifier.methods import classify_consensus_vsearch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_results(path):\n",
    "    \"\"\"From a mockrobiota expected results fasta file, load sequences and their\n",
    "    scientific name into a dataframe\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: path to the expected fasta file; str\n",
    "    \"\"\"\n",
    "    \n",
    "    sequences = []\n",
    "    genera = []\n",
    "    species_list = []\n",
    "\n",
    "    with open(path) as expected: \n",
    "        for line in expected:\n",
    "            #this is a header line; strip the > and newline character from it\n",
    "            if line.startswith('>'):\n",
    "                line = line.strip('>')\n",
    "                line = line.strip('\\n')\n",
    "                #capture each word in the header into a list. The first two\n",
    "                #words are the scientific name\n",
    "                line_list = re.split(' |_', line)\n",
    "                genus, species = line_list[:2]\n",
    "                genera.append(genus)\n",
    "                species_list.append(species)\n",
    "            else:\n",
    "                sequence = line.strip('\\n')\n",
    "                sequences.append(sequence)\n",
    "    #we're left with 3 lists that we can combine into a dataframe\n",
    "    results = pd.DataFrame(list(zip(sequences, genera, species_list)),\n",
    "                           columns = ['sequence', 'genus', 'species'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(path):\n",
    "\n",
    "    \"\"\"given the path of a 'representative sequences' quality controlled qiime2 artifact,\n",
    "    return a dictionary with the hashes mapped to the sequences\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the filepath of the .qza file exported from the rep_seqs artifact; str\n",
    "    \"\"\"\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp = Artifact.load(path)\n",
    "        temp.export_data(temp_dir)\n",
    "        \n",
    "        hashes = []\n",
    "        sequences = []\n",
    "        with open(temp_dir + '/dna-sequences.fasta') as sequence_file:\n",
    "            for line in sequence_file:\n",
    "                if line.startswith('>'):\n",
    "                    hashed_seq = line.lstrip('>')\n",
    "                    hashed_seq = hashed_seq.rstrip('\\n')\n",
    "                    hashes.append(hashed_seq)\n",
    "                else:\n",
    "                    sequences.append(line.rstrip('\\n'))\n",
    "        results = dict(zip(hashes, sequences))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assigned_taxonomy(classification_taxonomy, sequence_keys):\n",
    "    \"\"\"given a 'classification taxonomy' qiime2 artifact and a hash-sequence\n",
    "    dict, return a dataframe of sequences plus their 7-level taxonomy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    classification_taxonomy: an artifact created by a qiime2 feature-classifer\n",
    "                             method; FeatureData[Taxonomy] artifact\n",
    "    \n",
    "    sequence_keys: a dict of the hashes mapped to the full sequence; dict\n",
    "    \"\"\"\n",
    "    \n",
    "    hashes = []\n",
    "    taxonomy_strings = []\n",
    "    sequences = []\n",
    "    domains = []\n",
    "    phyla = []\n",
    "    classes = []\n",
    "    orders = []\n",
    "    families = []\n",
    "    genera = []\n",
    "    species_list = []\n",
    "    hierarchy = ['k','p','c','o','f','g','s']\n",
    "    #I'm not familiar enough with the API to extract the necessary data directly\n",
    "    #from the artifact, so I export it to a temporary directory and grab the tsv\n",
    "    #file from there.\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        classification_taxonomy.export_data(temp_dir)\n",
    "        with open(temp_dir + '/taxonomy.tsv') as taxonomy_file:\n",
    "            for line in taxonomy_file:\n",
    "                #Feature ID is the header row\n",
    "                if not line.startswith('Feature ID'):\n",
    "                    #these are the columns, we capture them in a list. Since the\n",
    "                    #final result is a dataframe, it might be more reasonable to\n",
    "                    #import into a df, but I think dfs get pretty messy pretty\n",
    "                    #quick when you start manipulating them. I'm also not sure\n",
    "                    #about the relative speed of operations\n",
    "                    hashed_sequence, taxonomy_string, consensus = line.split('\\t')\n",
    "                    hashes.append(hashed_sequence)\n",
    "                    taxonomy_strings.append(taxonomy_string)\n",
    "    #find the sequence associated with the hash and build a list of the actual\n",
    "    #sequences\n",
    "    for hashed_sequence in hashes:\n",
    "        sequence = sequence_keys[hashed_sequence]\n",
    "        sequences.append(sequence)\n",
    "    #here i expand out each string to an excessive number of unassigneds to\n",
    "    #ensure that there are at least 7 levels in every string, then capture the\n",
    "    #first seven assignments into their respective level. Lots of formatting\n",
    "    #adjustments.\n",
    "    for taxonomy_string in taxonomy_strings:\n",
    "        if taxonomy_string.startswith('Unassigned'):\n",
    "            domain = 'Unassigned'\n",
    "            phylum = 'Unassigned'\n",
    "            taxon_class = 'Unassigned'\n",
    "            order = 'Unassigned'\n",
    "            family = 'Unassigned'\n",
    "            genus = 'Unassigned'\n",
    "            species = 'Unassigned'\n",
    "        else:\n",
    "            temp_string = taxonomy_string + ';Unassigned' * 6\n",
    "            for rank in hierarchy:\n",
    "                temp_string = temp_string.replace((rank + \"__; \"), \"\")\n",
    "                temp_string = temp_string.replace((rank + \"__\"), \"\")\n",
    "            temp_string = temp_string.replace('; ;', ';Unassigned;')\n",
    "            domain, phylum, taxon_class, order, family, genus, species, _ = temp_string.split(';', 7)\n",
    "        domain = domain.lstrip('D_0')\n",
    "        phylum = phylum.lstrip('D_1')\n",
    "        taxon_class = taxon_class.lstrip('D_2')\n",
    "        order = order.lstrip('D_3')\n",
    "        family = family.lstrip('D_4')\n",
    "        genus = genus.lstrip('D_5')\n",
    "        species = species.lstrip('D_6')\n",
    "        domains.append(domain)\n",
    "        phyla.append(phylum)\n",
    "        classes.append(taxon_class)\n",
    "        orders.append(order)\n",
    "        families.append(family)\n",
    "        genera.append(genus)\n",
    "        species_list.append(species)\n",
    "    results = pd.DataFrame(list(zip(sequences, domains, phyla, classes, orders,\n",
    "                                    families, genera, species_list)),\n",
    "                           columns =['sequence', 'domain', 'phylum', 'class',\n",
    "                                     'order', 'family', 'genus', 'species'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_match(observed_df, expected_df, level):\n",
    "    \"\"\"Compare two dataframes at the specified taxonomic level. Dataframes are\n",
    "    matched by searching the observed sequence against the expected sequence.\n",
    "    Returns a list of the number of true positives, false positives, false\n",
    "    negatives, and sequences that could not be matched.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    observed_df: dataframe with sequence and taxonomy columns, taken from a\n",
    "                 classification-taxonomy artifact; df\n",
    "    expected_df: dataframe with sequence and taxonomy columns, taken from a\n",
    "                 mockrobiota expected-taxonomy file; df\n",
    "    level: taxonomic level at which to compare dataframes; str or int.\n",
    "    \"\"\"\n",
    "    #if the classfier correctly annotated the sequence, it's a true positive\n",
    "    true_positives = 0\n",
    "    #if the classifier couldn't assign it, we're calling it a false negative\n",
    "    false_negatives = 0\n",
    "    #if the classifier assigned it but got it wrong it is a false positive\n",
    "    false_positives = 0\n",
    "    #some observed sequences are not found in the expected taxonomy file. not\n",
    "    #sure if this is due to the quality control steps or some other aspect. it\n",
    "    #should not differ across references.\n",
    "    unmatched=0\n",
    "\n",
    "    #if an integer was passed as taxonomic level, convert it to the string\n",
    "    if type(level) == int:\n",
    "        levels = {1:'kingdom', 2:'phylum', 3:'class', 4:'order', 5:'family',\n",
    "                  6:'genus', 7:'species'}\n",
    "        level = levels[level]\n",
    "\n",
    "    #iterate down the observed dataframe\n",
    "    for row in observed_df.iterrows():\n",
    "        #grab the value from the 'sequence' column of the observed df\n",
    "        query_seq = row[1]['sequence']\n",
    "        #search the expected dataframe for that sequence and grab that row\n",
    "        seq_match = (expected_df[expected_df['sequence'].str.contains(query_seq)])\n",
    "        seq_match = seq_match.reset_index(drop=True)\n",
    "        #if there's no match, the df will be empty. if not, we have a match\n",
    "        if not seq_match.empty:\n",
    "            #grab the assigned taxonomic name at the specified level\n",
    "            query = row[1][level]\n",
    "            #grab the reference taxonomic name at the specified level\n",
    "            expected = seq_match.loc[0][level]\n",
    "            if query == 'Unassigned':\n",
    "                false_negatives += 1\n",
    "            elif query != expected:\n",
    "                false_positives += 1\n",
    "            elif query == expected:\n",
    "                true_positives += 1\n",
    "        #if the dataframe was empty the sequence couldn't be matched\n",
    "        else:\n",
    "            unmatched += 1\n",
    "    #store the results in a list\n",
    "    results = [true_positives, false_positives, false_negatives, unmatched]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/mnt/c/Users/Dylan/Documents/zaneveld/GCMP_Global_Disease-master/analysis/organelle_removal'\n",
    "list_of_mocks = [12]\n",
    "                 #,13,14,15,16,18,19,20,21,22]\n",
    "references = ['silva', 'silva_metaxa2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running external command line application. This may print messages to stdout and/or stderr.\n",
      "The command being run is below. This command cannot be manually re-run as it will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: vsearch --usearch_global /tmp/qiime2-archive-xh9q7v5g/56f99adf-238a-45b9-bf99-6185e4b56c66/data/dna-sequences.fasta --id 0.8 --query_cov 0.8 --strand both --maxaccepts 10 --maxrejects 0 --db /tmp/qiime2-archive-e3ezu86c/d4169954-89dd-402a-bccb-af1bf96b9731/data/dna-sequences.fasta --threads 4 --output_no_hits --blast6out /tmp/tmpo7oj88s3\n",
      "\n",
      "Running external command line application. This may print messages to stdout and/or stderr.\n",
      "The command being run is below. This command cannot be manually re-run as it will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: vsearch --usearch_global /tmp/qiime2-archive-xh9q7v5g/56f99adf-238a-45b9-bf99-6185e4b56c66/data/dna-sequences.fasta --id 0.8 --query_cov 0.8 --strand both --maxaccepts 10 --maxrejects 0 --db /tmp/qiime2-archive-yoqgcwn1/4a93ff96-30cd-42d9-85f1-1846d10d1633/data/dna-sequences.fasta --threads 4 --output_no_hits --blast6out /tmp/tmpi6b73z91\n",
      "\n",
      "Running external command line application. This may print messages to stdout and/or stderr.\n",
      "The command being run is below. This command cannot be manually re-run as it will depend on temporary files that no longer exist.\n",
      "\n",
      "Command: vsearch --usearch_global /tmp/qiime2-archive-7rlhpwju/56f99adf-238a-45b9-bf99-6185e4b56c66/data/dna-sequences.fasta --id 0.8 --query_cov 0.8 --strand both --maxaccepts 10 --maxrejects 0 --db /tmp/qiime2-archive-pokqucsx/d4169954-89dd-402a-bccb-af1bf96b9731/data/dna-sequences.fasta --threads 4 --output_no_hits --blast6out /tmp/tmpn8253s2w\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8f8904195c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             f_measure = 2 * ((precision * recall) / (precision +\n\u001b[0;32m---> 31\u001b[0;31m                                                      recall))\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmock_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reference'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'true_positives'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false_positives'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'false_negatives'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f_measure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unmatched'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for level in ['genus', 'species']:\n",
    "    for mock_number in list_of_mocks:\n",
    "        path = (working_dir + '/tax-credit/data/mock-community/mock-' +\n",
    "                str(mock_number) + '/expected-sequences.fasta')\n",
    "        #load the expected results into a dataframe\n",
    "        expected_results = get_expected_results(path)\n",
    "        #load the rep_seqs into variable\n",
    "        seqs_path = (working_dir + '/mock-community/mock-' +\n",
    "                     str(mock_number) + '/rep_seqs.qza')\n",
    "        seq_artifact = Artifact.load(seqs_path)\n",
    "        sequence_keys = get_sequences(seqs_path)\n",
    "        for reference in references:\n",
    "            reference_read_path = (working_dir + '/output/taxonomy_references/' + reference +\n",
    "                                   '_otus.qza')\n",
    "            reference_reads = Artifact.load(reference_read_path)\n",
    "            reference_taxonomy_path = (working_dir + '/output/taxonomy_references/' +\n",
    "                                       reference + '_taxonomy.qza')\n",
    "            reference_taxonomy = Artifact.load(reference_taxonomy_path)\n",
    "            classification_taxonomy, = classify_consensus_vsearch(query = seq_artifact,\n",
    "                                                                  reference_reads = reference_reads,\n",
    "                                                                  reference_taxonomy = reference_taxonomy,\n",
    "                                                                  threads = 4) \n",
    "            df = get_assigned_taxonomy(classification_taxonomy = classification_taxonomy,\n",
    "                                       sequence_keys = sequence_keys)\n",
    "            tp, fp, fn, u = calculate_match(df, expected_results,\n",
    "                                            level)\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)\n",
    "            f_measure = 2 * ((precision * recall) / (precision +\n",
    "                                                     recall))\n",
    "            stats.append([mock_number, reference, tp, fp, fn, precision, recall, f_measure, u, level])\n",
    "results_df = pd.DataFrame(stats, columns =['mock', 'reference', 'true_positives', 'false_positives', 'false_negatives', 'precision', 'recall', 'f_measure', 'unmatched', 'level'])\n",
    "results_df.to_csv('compare_accuracy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_df.loc[:,['f_measure', 'level', 'mock', 'reference']]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(results, col='mock', hue = 'reference', col_wrap = 4, height = 1.5, legend_out = True)\n",
    "grid.map(plt.plot, \"level\", \"f_measure\", marker = \"o\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "sns.set_context(\"poster\")\n",
    "d = {\"ls\" : [\"dashed\",\"dotted\"]}\n",
    "grid = sns.FacetGrid(results, col='mock', hue = 'reference', col_wrap = 4, height = 3, hue_kws=d)\n",
    "g = grid.map(plt.plot, \"level\", \"f_measure\", marker = \"+\").add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
